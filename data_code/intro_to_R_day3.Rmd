---
title: "Intro to R Day 3"
output:
      html_document:
        keep_md: true
---

```{r}
library(tidyverse)

### Reading in other datasets
library(haven)
library(readxl)
library(httpuv)
library(googlesheets4)

### Missing data
library(visdat)
library(naniar)

### Functions for visualizing regression
library(gtsummary)
library(sjPlot)
library(interactions)
library(cardx)
library(randomNames)
```

## Reading other data sources 

From the `haven` documentation: [https://haven.tidyverse.org/reference/index.html](https://haven.tidyverse.org/reference/index.html)

### Labelled vectors

SAS, SPSS, and Stata share a simply concept of “labelled” vectors, which are similar to factors but a little more general. The `labelled()` class provides a natural representaion in R.

`labelled_spss()`
    Labelled vectors for SPSS

`labelled()` `is.labelled()`
    Create a labelled vector.

`print_labels()`
    Print the labels of a labelled vector

`as_factor(<data.frame>)` `as_factor(<haven_labelled>)` `as_factor(<labelled>)`
    Convert labelled vectors to factors

### Tagged missing values

Both SAS and Stata supported tagged missing values, where a missing value can have multiple “types”, given by an letter from A through Z. `tagged_na()` provides a convenient way of representing these types of missing values in R by taking advantage of the binary representation of NA.

`tagged_na()` `na_tag()` `is_tagged_na()` `format_tagged_na()` `print_tagged_na()`
    "Tagged" missing values

Remove attributes

__There are a number of SPSS/SAS/Stata features that have no direct equivalent in R.__ Haven preserves them so you can choose what do with them. To simply eliminate them, use one of the zap functions.

`zap_empty()`
    Convert empty strings into missing values

`zap_formats()`
    Remove format attributes

`zap_label()`
    Zap variable labels

`zap_labels()`
    Zap value labels

`zap_missing()`
    Zap special missings to regular R missings

`zap_widths()`
    Remove display width attributes 

### Read SPSS Data

```{r}
data_spss <- read_sav("data_spss.sav")
```

### Read SAS Data

SAS has two data formats, `xpt` and `sas7bdat` formats. Here we are only going to how the `xpt` method but it's very similar. 

```{r}
data_sas <- read_xpt("data_sas.xpt")
```

### Read Stata

```{r}
data_stata <- read_dta("data_stata.dta")
```

### Read Excel

This is from the `readxl` package. Extremely powerful for reading in excel files. 

```{r}
data_excel <- read_excel("data_all.xlsx", sheet = "data_all")
```

### Read Google Sheets

To get Google Sheets package to work we need to authenticate our Google Drive. The sheet needs to be shared to this can get a bit complicated. If it's in your own Google Sheets that's easy enough. 

##### NOT RUN

```{}
data_google <- read_sheet("https://docs.google.com/spreadsheets/d/1vGwx9rpdKX--wqS0LShyXbwm_GSG-tiNuiBdwSk7xPY/edit?gid=391891818#gid=391891818")
```

## Missing Data

So far we have not included any missing data. In the real world there will definitely by missingness in your data. R handles missing data a bit differently from the other common software. 

```{r}
data_missing <- read_csv("data_missing.csv")
```

## Ways R encodes missing(ish) data

### NaN and Inf are related to NA.

#### NaN

NaN represents `Not a Number`. NaN can be generated, for example, by taking the log of a negative number. They can be tested for with is.nan()

```{r}
x <- log(c(1, -1, NA))
x
is.nan(x)
```

#### Inf

Inf and -Inf represent positive and negative infinite numbers respectively. These can be generated, for example, by dividing by zero, and tested for with is.infinite()

```{r}
y <- c(-Inf, 0, Inf)
is.infinite(y)
```

### Comparison of missing types

The test is.finite() it TRUE if the value is numeric and not NA, NaN, Inf or -Inf.

 value |	is.na |	is.nan |	is.infinite |	is.finite 
 ----- | ------ | ------ | ------ 
 1 	| FALSE |	FALSE |	FALSE |	TRUE
 NA 	| TRUE |	FALSE |	FALSE |	FALSE
 NaN |	TRUE |	TRUE |	FALSE |	FALSE
 Inf |	FALSE |	FALSE |	TRUE |	FALSE
 -Inf |	FALSE |	FALSE |	TRUE |	FALSE

## Missing data analysis

#### We want a quick summary of missing data for each variable. This function is from the `naniar` package. We have lots of variables so let's save this as a table that we inspect a little easier. 

```{r}
missing_table <- miss_var_summary(data_missing)
missing_table
```

Now that we have a more manageable dataframe let's visualize missing with the package `visdat` to quickly visualize the entire dataframe and check missing.

```{r}
vis_dat(data_missing)
```

We have fixed the problem with logical variables and those with too much missing to do anything with really. Now let's move on to what we can actually do. 

## You got some SPSS data! 

When you are dealing with missing values, you might want to replace values with a missing values (NA). This is useful in cases when you know the origin of the data and can be certain which values should be missing. For example, you might know that all values of “N/A”, “N A”, and “Not Available”, or -99, or -1 are supposed to be missing.

naniar provides functions to specifically work on this type of problem using the function replace_with_na. This function is the compliment to tidyr::replace_na, which replaces an NA value with a specified value, whereas naniar::replace_with_na replaces a value with an NA:

* `tidyr::replace_na`: Missing values turns into a value (NA –> -99)
* `naniar::replace_with_na`: Value becomes a missing value (-99 –> NA)


## Data Wrangling 

Let's say we have a bunch of different datasets we need to combine together in some way. There are many ways to do this. The cheat sheet for `dplyr` can help with this. It provides nice visuals if you are trying to combine datasets. Here is a snip of it. The full cheat sheet is available here [https://rstudio.github.io/cheatsheets/html/data-transformation.html](https://rstudio.github.io/cheatsheets/html/data-transformation.html)

![](cheat_sheet.png)

```{r}
data1 <- read_csv("dataset1.csv")
```

### Joining datasets

#### Stacking 2 datasets on top of each other

If we want to stack two datasets we need to use the `bind` set of functions. We can either use `bind_rows` or `bind_cols` from the `tidyverse` set of packages to do this. Let's say we have two datasets with the same information but different participants. We want to stack them so we can do some bigger analysis. 

```{r}
data2 <- read_csv("dataset2.csv")
data3 <- read_csv("dataset3.csv")
data4 <- read_csv("dataset4.csv")
```

Data1 and Data2 have the some number and information in the columns but they are not together. We can join them using `bind_rows`. Some notes on this

* All variables need to have the same name
* Variables with the same name need to have the same type (eg. numeric)
    * If you have a variable names `id` and it's factor in one dataset and numeric in the other the function will not work
* All variables need to be in all datasets
    * If you have a `cholestrol` variable that is only in one dataset the function will not work

```{r}
data_all <- bind_rows(data1, data2, data3, data4)

#write_csv(data_all, "data_all.csv")
```

#### Advanced

We can also do more advanced things like select and bind all of the files in a folder with a specific filename or file extension. 

```{r}
paths <- list.files(pattern = "dataset.*\\.csv", full.names = TRUE)
paths

files <- map(paths, read_csv)
length(files)

data_test <- list_rbind(files)
summary(data_test)

#write_csv(data_all, "data_all.csv")
```

2. Join by ID

If you have 2 datasets with different data that you want to join you can use different join methods. These terms are from computer science. `full_join`, `left_join`, `right_join`, etc. 

```{r}
names_data <- read_csv("names.csv")
glimpse(names_data)

data_all <- left_join(data_all, names_data, by = join_by(id))
table(data_all$parent)
```

## Data Viz

### 1. ggplot2 General

ggplot2 is an open-source data visualization package for the statistical programming language R. Created by Hadley Wickham in 2005, ggplot2 is an implementation of Leland Wilkinson's Grammar of Graphics—a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers.[Wikipedia](https://en.wikipedia.org/wiki/Ggplot2) The basic idea is to build plots layer by layer. With ggplot2 you can control absolutely everything about a plot. 

Data viz is a big place where R and Stata diverge a lot. With R giving much more flexibility (and sometimes annoyance) in terms of visualizing data. We are going to cover basics but recommend the BBC Code Book [https://bbc.github.io/rcookbook/](https://bbc.github.io/rcookbook/) and Keiran Healey's book _Data Visualization_ [https://kieranhealy.org/publications/dataviz/](https://kieranhealy.org/publications/dataviz/) which is part of the the `socviz` package [https://kjhealy.github.io/socviz/](https://kjhealy.github.io/socviz/. )

### 2. Histograms and single variable box plots

ggplot2 is built on things called *geoms* which represent different types of plots. There are *geoms* for histograms, scatterplots, beeswarm, and many other plots. Here we are focusing two basic plots and the defaults of everything else. 

#### Single bar graphs

People get stuck in R making bar graphs because they are used to Excel and only have the mean value of a given column then making the bar graph from that mean column. It's always questionnable whether you should be making a bar graph, but if you really need to here is how you can do it in R. 

```{r}
# Recoding income here so we can see the levels more easily

data_all <- data_all %>%
	mutate(stroke_recode = case_when(
		stroke == "1" ~ "Yes",
    stroke == "0" ~ "No"
	))

data_all$stroke_recode <- as_factor(data_all$stroke_recode)

table(data_all$stroke, data_all$stroke_recode)
```

```{r}
bar_stroke <- ggplot(data_all, aes(stroke_recode)) + 
                geom_bar() + 
                labs(x = "Has had a stroke") + 
                theme(axis.text.x = element_text(angle = 90))       
plot(bar_stroke)
```

#### Single variable boxplots

```{r}
boxplot <- ggplot(data_all, aes(stroke_recode)) + 
              geom_boxplot() + 
              coord_flip()  # Here we add coord_flip function to make the boxplot more as we would expect
plot(boxplot)
```

#### Two variable boxplots

Very useful for showing mean differences and presenting stuff with ANOVA type analysis. 

```{r}
boxplot_stroke <- ggplot(data_all, aes(x = age, y = stroke_recode, colour = stroke_recode)) + 
              geom_boxplot() + 
              coord_flip() + # Here we add coord_flip function to make the boxplot more as we would expect
              theme_classic()
plot(boxplot_stroke)
```

### 3. Scatter plots

Scatterplots plot the relationship between two variables. There are lots of things we can do and we will build a plot sequentially. We are going to plot the relationship between age and physical activity (two continuous variables). 

```{r}
scatter_plot <- ggplot(data_all, aes(x = age, y = ldl1)) + 
                  geom_point(position=position_jitter())
plot(scatter_plot)
```

Common things you will see with a scatter plot including the following

#### Adding a regression line

Here we add another *geom* on top of the *geom_point* to start building our plot. We will use *geom_smooth* to add a line. The default in R is a lowess smoother. You can also add a linear regression line. I'm also changing the colour so we can see the difference between the two lines. It's best to use hexcodes for colours but we can also just use words. 

```{r}
scatter_plot_line <- ggplot(data_all, aes(x = age, y = ldl1)) + 
                  geom_point(position = position_jitter()) + 
                  geom_smooth(colour = "red") + 
                  geom_smooth(method = "lm", colour = "#088da5")
plot(scatter_plot_line)
```

#### Changing the variable names

```{r}
scatter_plot_variables <- ggplot(data_all, aes(x = age, y = ldl1)) + 
                  geom_point(position = position_jitter()) + 
                  geom_smooth(colour = "red") + 
                  geom_smooth(method = "lm", colour = "#088da5") +
                  labs(x = "Age", y = "LDL Cholesterol")
plot(scatter_plot_variables)
```

#### Changing the shading of the points

We can use *alpha* to change the shading of the points. This lets use quickly avoid overplotting with lots of overlapping points. We need to play with this a bit. A good place to start is 0.5 and go from there. I ended up at 0.2 which I think shows the mass of data points and avoids too much emphasis on the outlier points. 

```{r}
scatter_plot_alpha <- ggplot(data_all, aes(x = age, y = ldl1)) + 
                  geom_point(alpha = 0.2, position = position_jitter()) + 
                  geom_smooth(colour = "red") + 
                  geom_smooth(method = "lm", colour = "#088da5") +
                  labs(x = "Age", y = "LDL Cholesterol")
plot(scatter_plot_alpha)
```

### 4. Grouping with ggplot2

One of the best things about ggplot2 is the ability to easily *group_by* like we would do with data wrangling. We do this by adding groupings (colouring by a variable) or facets (creating separate plots). Here we want to group by gender to see if there are visual differences between genders in the age-PA association. 

Colouring by gender
```{r}
scatter_plot_gender <- ggplot(data_all, aes(x = age, y = ldl1, colour = stroke_recode)) + 
                  geom_point(alpha = 0.2, position = position_jitter()) + 
                  labs(x = "Age", y = "LDL Cholesterol", fill = "Stroke") 
plot(scatter_plot_gender)
```

Faceting by gender
```{r}
scatter_plot_gender <- ggplot(data_all, aes(x = age, y = ldl1)) + 
                  geom_point(alpha = 0.2, position = position_jitter()) + 
                  labs(x = "Age", y = "LDL Cholesterol") +
                  facet_wrap(~ stroke_recode)
plot(scatter_plot_gender)
```

### 5. Colours and themes

Finally, there are many default colours and themes we can use to make the plots look good very quickly. A few things I use regularly. 

#### Themes

There are two themes I use regularly; *classic* and *bw*. Classic provides a clean looking plot with no/limited background. *bw* provides a black and white figure, which is great for publications that need no colour. 

**Black and White Theme**

```{r}
scatter_plot_bw <- ggplot(data_all, aes(x = age, y = ldl1, colour = stroke_recode)) + 
                  geom_point(alpha = 0.2, position = position_jitter()) + 
                  labs(x = "Age", y = "LDL Cholesterol", colour = "Stroke") +
                  theme_bw()
plot(scatter_plot_bw)
```

**Classic Theme**

```{r}
scatter_plot_classic <- ggplot(data_all, aes(x = age, y = ldl1, colour = stroke_recode)) + 
                  geom_point(alpha = 0.2, position = position_jitter()) + 
                  labs(x = "Age", y = "LDL Cholesterol", colour = "Stroke") +
                  theme_classic()
plot(scatter_plot_classic)
```

#### Colours

There are lots of default colours in R. The basic functions are *scale_colour* and *scale_fill*. We didn't talk about this much but colour and fill are different based what you are filling. If we go back to the gender colouring we can use different functions to change the colours. The colour brewer colours [https://colorbrewer2.org/](https://colorbrewer2.org/) using *scale_colour_brewer* or *scale_fill_brewer* for sensible default colours. 

```{r}
scatter_plot_gender_brewer <- ggplot(data_all, aes(x = age, y = ldl1, colour = stroke_recode)) + 
                  geom_point(alpha = 0.2, position = position_jitter()) + 
                  scale_colour_manual(values = c("#E69F00", "#56B4E9")) +
                  labs(x = "Age", y = "LDL Cholesterol", colour = "Stroke") 
plot(scatter_plot_gender_brewer)
```

### 6. Heat Maps 

Someone asked about heat maps so here is an example. A heatmap is a row and column look at the data so we need to do some reshaping and selecting the data in order for this to work. We are only going to use age, ldl1, and ldl2 for this to keep things simple. 

```{r}
data_heat <- data_all %>% select(id, ldl1, ldl2)

data_heat <- data_heat %>%
                dplyr::mutate(id = row_number()) %>%
                gather(-id, key = "key", value = "val") %>%
                mutate(isna = is.na(val)) 

ggplot(data = data_heat, aes(id, key, fill = val)) +
    geom_tile(alpha=1) +
    labs(x = "Person", y = "LD 1 and 2") +
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) 
```

## Regression stuff 

### Creating a table of bivariable associations

We always want to look at all of the bivariate associations for each independent variable. We can do this quickly with the final fit package. For now ignore the multivariable model results. We just want to look at the bivariable. 

```{r}
univ_table <- data_all %>%
  select(ldl1, sex, ethgrp, age, smoking, Cancer, stroke_recode) %>%
  tbl_uvregression(
    method = glm,
    y = ldl1,
    method.args = list(family = gaussian)) 

univ_table %>% as_kable()
```

### Creating a final model

Here we can create a final model and plot the model results along with our 

```{r}
model_final <- glm(ldl1 ~  sex +
                           ethgrp + 
                           age + 
                           smoking + 
                           Cancer + 
                           stroke_recode, 
                    data = data_all, family = "gaussian")

summary(model_final)

multi_table <- tbl_regression(model_final) 

multi_table %>% as_kable()
```

### Plot a final model

We might also want to plot the results of the final model as coefficients and confidence intervals instead of showing the model in table. Can be a nice way to present the results. We are going to use the `plot_model` from the `sjPlot` package. This package leverages `ggplot2` but probably goes not offer quite as much flexibility. 

```{r}
plot_model(model_final, type="est")
```

## Interaction terms

We might want to check for interaction terms. There might be an interaction between smoking and cancer so let's test that our dataset, visualize the interaction, and compare to both our bivariable models and final model. 

```{r}
model_interaction <- glm(ldl1 ~  sex +
                           ethgrp + 
                           age + 
                           smoking + 
                           Cancer + 
                           smoking*Cancer + 
                           stroke_recode, 
                    data = data_all, family = "gaussian")

summary(model_interaction)

inter_table <- tbl_regression(model_interaction) 

inter_table %>% as_kable()
```

### Visualize interaction term

```{r}
plot_interaction <- interact_plot(model_interaction, 
                                    pred = smoking, 
                                    modx = Cancer, 
                                    plot.points = TRUE, 
                                    partial.residuals = TRUE, 
                                    interval = TRUE,
                                    int.width = 0.95)
plot(plot_interaction)
```

## Putting it all together

We might want to make a big table with our bivariable analysis, final model, and interaction model for presentation or quickly show results. We can do that by combining tables

```{r}
tbl_univ_multi_inter <- tbl_merge(list(univ_table, multi_table, inter_table))

tbl_univ_multi_inter %>% as_kable()
```

For linear regression models there are a number of assumptions we want to check. These are typically easy visualized using plots. We can produce the plots for the relevant visualizations using `plot` from base R or by using 

```{r}
plot(model_final)
```
